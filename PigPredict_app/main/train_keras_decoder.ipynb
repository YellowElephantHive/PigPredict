{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from skimage import color\n",
    "\n",
    "import keras\n",
    "from keras import regularizers, losses\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Reshape\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ProgbarLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 取得專案目錄，方便管理並匯入自訂套件 \"\"\"\n",
    "prj_root = os.path.join(os.getcwd(), os.pardir)\n",
    "sys.path.append(prj_root)\n",
    "import preprocess.dyeprocess as dyeprocess\n",
    "from util.normalize import unnormalize_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 參數設定 \"\"\"\n",
    "MIN_OCCUR = 0\n",
    "BATCH_SIZE = 128\n",
    "PATIENCE = 500\n",
    "EPOCHS = 10000\n",
    "SEED = 88\n",
    "\n",
    "DATA_FILE_ALL = os.path.join(prj_root, 'data', 'hong_make_all_revised_3.csv')\n",
    "DATA_FILE_SINGLE = os.path.join(prj_root, 'data', 'hong_make_single_revised_3.csv')\n",
    "DECODER_INPUT_COLUMNS_PATH = os.path.join(prj_root, 'resource', 'pickled', 'decoder_input_columns.pkl')\n",
    "LAB_MEAN_PATH = os.path.join(prj_root, 'resource', 'pickled', 'lab_mean.pkl')\n",
    "LAB_STD_PATH = os.path.join(prj_root, 'resource', 'pickled', 'lab_std.pkl')\n",
    "X_VAL_PATH = os.path.join(prj_root, 'resource', 'pickled', 'decoder_x_val.pkl')\n",
    "Y_VAL_PATH = os.path.join(prj_root, 'resource', 'pickled', 'decoder_y_val.pkl')\n",
    "CKP_PATH = os.path.join(prj_root, 'resource', 'keras_model', 'keras_decoder_model_tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load data \"\"\"\n",
    "df_all = pd.read_csv(DATA_FILE_ALL)\n",
    "df_all = df_all[df_all['abort']!=1]\n",
    "df_all = df_all[df_all['L'].notnull()]\n",
    "\n",
    "df_single = pd.read_csv(DATA_FILE_SINGLE)\n",
    "df_single = df_single[df_single['abort']!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 將濃度轉成濃度向量，並把布號 one hot encoding \"\"\"\n",
    "df_all_one_hot = dyeprocess.df_dye_one_hot_with_concetration(df_all, df_all, df_single, min_occur=MIN_OCCUR)\n",
    "df_single_one_hot = dyeprocess.df_dye_one_hot_with_concetration(df_single, df_all, df_single, min_occur=MIN_OCCUR)\n",
    "\n",
    "# 去除沒有染料資料的 sample\n",
    "# -0 結尾代表是想要染的對象，所以不會有染料的資料\n",
    "df_all_one_hot = df_all_one_hot[np.logical_not(df_all_one_hot['LAB'].str.contains('-\\s*0\\s*$', case=True, regex=True))]\n",
    "\n",
    "df_all_one_hot = pd.concat([df_all_one_hot, pd.get_dummies(df_all_one_hot['單色光'])], axis=1)\n",
    "df_single_one_hot = pd.concat([df_single_one_hot, pd.get_dummies(df_single_one_hot['布號'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 取得 model 要用的 input x 和 output y \"\"\"\n",
    "x = pd.concat([df_all_one_hot.filter(regex='^concentration|^FVF'), df_single_one_hot.filter(regex='^concentration|^FVF')])\n",
    "raw_y = pd.concat([df_all_one_hot[['L', 'a', 'b']], df_single_one_hot[['L', 'a', 'b']]])\n",
    "raw_y_mean = raw_y.mean()\n",
    "raw_y_std = raw_y.std()\n",
    "\n",
    "with open(DECODER_INPUT_COLUMNS_PATH, 'wb') as output:\n",
    "    pickle.dump(x.columns.values, output)\n",
    "with open(LAB_MEAN_PATH, 'wb') as output:\n",
    "    pickle.dump(raw_y_mean, output)\n",
    "with open(LAB_STD_PATH, 'wb') as output:\n",
    "    pickle.dump(raw_y_std, output)\n",
    "    \n",
    "# normalize y\n",
    "y = (raw_y - raw_y_mean) / raw_y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 切 training testing set \"\"\"\n",
    "single_df_start_idx = -1*len(df_single_one_hot)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x.iloc[:single_df_start_idx, :],\n",
    "                                                  y.iloc[:single_df_start_idx, :], \n",
    "                                                  test_size=0.1, \n",
    "                                                  random_state=SEED)\n",
    "\n",
    "# 把單色染料全部放入 training set\n",
    "x_train = pd.concat([x_train, x.iloc[single_df_start_idx:, :]])\n",
    "y_train = pd.concat([y_train, y.iloc[single_df_start_idx:, :]])\n",
    "\n",
    "with open(X_VAL_PATH, 'wb') as output:\n",
    "    pickle.dump(x_val, output)\n",
    "with open(Y_VAL_PATH, 'wb') as output:\n",
    "    pickle.dump(y_val, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 取得艷度高的 training set。 \"\"\"\n",
    "y_train_actual = y_train.copy().values\n",
    "y_train_actual[:, 0] = y_train_actual[:, 0] * raw_y_std['L'] + raw_y_mean['L']\n",
    "y_train_actual[:, 1] = y_train_actual[:, 1] * raw_y_std['a'] + raw_y_mean['a']\n",
    "y_train_actual[:, 2] = y_train_actual[:, 2] * raw_y_std['b'] + raw_y_mean['b']\n",
    "y_train_actual\n",
    "\n",
    "lch_train = color.lab2lch(y_train_actual)\n",
    "x_train_high_c = x_train.iloc[lch_train[:,1]>35, :].copy()\n",
    "y_train_high_c = y_train.iloc[lch_train[:,1]>35, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dimesion = len(x.columns)\n",
    "L1_REG = 0\n",
    "L2_REG = 1e-4\n",
    "LEAKY_RELU_VALUE = 0.5\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Dense(128, \n",
    "          input_shape=(vec_dimesion,), \n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG),\n",
    "          kernel_initializer=keras.initializers.he_normal(seed=SEED)),\n",
    "    LeakyReLU(LEAKY_RELU_VALUE),\n",
    "    Dense(128, \n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG),\n",
    "          kernel_initializer=keras.initializers.he_normal(seed=SEED)),\n",
    "    LeakyReLU(LEAKY_RELU_VALUE),\n",
    "    Dense(128, \n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG),\n",
    "          kernel_initializer=keras.initializers.he_normal(seed=SEED)),\n",
    "    LeakyReLU(LEAKY_RELU_VALUE),\n",
    "    Dense(128, \n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG),\n",
    "          kernel_initializer=keras.initializers.he_normal(seed=SEED)),\n",
    "    LeakyReLU(LEAKY_RELU_VALUE),\n",
    "    Dense(128, \n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG),\n",
    "          kernel_initializer=keras.initializers.he_normal(seed=SEED)),\n",
    "    LeakyReLU(LEAKY_RELU_VALUE),\n",
    "    Dense(128, \n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG),\n",
    "          kernel_initializer=keras.initializers.he_normal(seed=SEED)),\n",
    "    LeakyReLU(LEAKY_RELU_VALUE),\n",
    "    Dense(128,\n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG),\n",
    "          kernel_initializer=keras.initializers.he_normal(seed=SEED)),\n",
    "    LeakyReLU(LEAKY_RELU_VALUE),\n",
    "    Dense(32,\n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG),\n",
    "          kernel_initializer=keras.initializers.he_normal(seed=SEED)),\n",
    "    LeakyReLU(LEAKY_RELU_VALUE),\n",
    "    Dense(16,\n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG),\n",
    "          kernel_initializer=keras.initializers.he_normal(seed=SEED)),\n",
    "    LeakyReLU(LEAKY_RELU_VALUE),\n",
    "    Dense(3, \n",
    "          kernel_regularizer=keras.regularizers.l1_l2(l1=L1_REG, l2=L2_REG))])\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=5e-4)\n",
    "# sgd = keras.optimizers.SGD(lr=5e-4, decay=0, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss=losses.mean_absolute_error,\n",
    "              optimizer=opt)\n",
    "\n",
    "# LEAKY_RELU_VALUE 0.0 loss 1.9437939551700134\n",
    "# LEAKY_RELU_VALUE 0.05 loss 1.8192624274099036\n",
    "# LEAKY_RELU_VALUE 0.1 loss 1.9517180010487938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1)\n",
    "checkpoint = ModelCheckpoint(CKP_PATH, monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 先 train 艷度高的資料 \"\"\"\n",
    "model_history_1 = model.fit(x_train_high_c, \n",
    "                            y_train_high_c, \n",
    "                            int(len(x_train_high_c)/16), \n",
    "                            EPOCHS,                         \n",
    "                            validation_data=(x_val, y_val),\n",
    "                            callbacks=[checkpoint, earlystop],\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" train 所有資料 in training set \"\"\"\n",
    "model_history_2 = model.fit(x_train, \n",
    "                            y_train, \n",
    "                            BATCH_SIZE, \n",
    "                            EPOCHS,                         \n",
    "                            validation_data=(x_val, y_val),\n",
    "                            callbacks=[checkpoint, earlystop],\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 預測 validation set 的結果，並計算 delta E_lab \"\"\"\n",
    "bst_model = keras.models.load_model(CKP_PATH)\n",
    "y_pred = bst_model.predict(x_val)\n",
    "y_pred = unnormalize_lab(y_pred)\n",
    "\n",
    "y_val_true = unnormalize_lab(y_val.values)\n",
    "\n",
    "# delta E_Lab\n",
    "np.sqrt(((y_pred - y_val_true)**2).sum(axis=1)).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
